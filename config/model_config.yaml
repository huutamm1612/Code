llm_settings:
  llm_model: "SeaLLMs/SeaLLMs-v3-1.5B-Chat"
  max_tokens: 256
  top_k: 5,
  top_p: 0.9,
  temperature: 0.7,
  
embedding_settings:  
  embedding_model: "intfloat/multilingual-e5-base"
  chunk_size: 256
  chunk_overlap: 48

paths:
  faiss_index: "faiss_index/"
  data_source: "data/"
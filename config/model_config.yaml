llm_settings:
  llm_model: "phamhai/Llama-3.2-3B-Instruct-Frog"
  max_tokens: 256
  top_k: 5,
  top_p: 0.9,
  temperature: 0.7,
  
embedding_settings:  
  embedding_model: "BAAI/bge-m3"
  chunk_size: 256
  chunk_overlap: 48

cls_model_settings:
  model_save_path: "data/classification_model.pth"
  convnext_model: "convnext_base"
  swin_model: "swin_base_patch4_window7_224"
  n_classes: 206
  batch_size: 64
  epochs: 50
  n_classes: 5
  learning_rate: 0.0001
  weigh_decay: 0.0005
  step_size: 5
  gamma: 0.1
  seed: 42
  data_dir: "/kaggle/input/medicalplant-dataset/new_dataset-20251112T053539Z-1-001/new_dataset"
  map_file: "/kaggle/input/medicalplant-dataset/new_dataset-20251112T053539Z-1-001/class_mapping.json"

paths:
  medical_info_path: "data/medical plan.csv"
  faiss_index: "faiss_index/"
  data_source: "data/"